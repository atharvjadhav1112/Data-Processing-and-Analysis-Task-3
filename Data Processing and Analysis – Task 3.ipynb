{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ba4957-fe00-4342-aeff-01b02bce2d5b",
   "metadata": {},
   "source": [
    "# Problem 1: Employee Performance Bonus Eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1e1b8d-4086-4d6a-b895-116e08cc79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Performers Eligible for Bonus: Ravi, Kiran (Score: 92)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1: Employee Performance Bonus Eligibility\n",
    "\n",
    "def employee_bonus_eligibility(employees):\n",
    "    \"\"\"\n",
    "    Identifies employees eligible for top performance bonus.\n",
    "    Handles tie cases automatically.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Find highest performance score\n",
    "    highest_score = max(employees.values())\n",
    "    \n",
    "    # Step 2: Identify all employees with highest score\n",
    "    top_performers = [name for name, score in employees.items() if score == highest_score]\n",
    "    \n",
    "    # Step 3: Display result\n",
    "    print(\"Top Performers Eligible for Bonus:\", \", \".join(top_performers), f\"(Score: {highest_score})\")\n",
    "\n",
    "\n",
    "# Input\n",
    "employees = {\n",
    "    \"Ravi\": 92,\n",
    "    \"Anita\": 88,\n",
    "    \"Kiran\": 92,\n",
    "    \"Suresh\": 85\n",
    "}\n",
    "\n",
    "employee_bonus_eligibility(employees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f75706-d929-4413-a6f1-4f4823eef2d2",
   "metadata": {},
   "source": [
    "# Problem 2: Search Query Keyword Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97032327-53fd-40eb-b450-9808a447f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'buy': 2, 'phone': 2}\n"
     ]
    }
   ],
   "source": [
    "# Problem 2: Search Query Keyword Analysis\n",
    "\n",
    "import string\n",
    "\n",
    "def keyword_analysis(query):\n",
    "    \"\"\"\n",
    "    Analyzes keyword frequency from search query.\n",
    "    Ignores punctuation and converts to lowercase.\n",
    "    Displays keywords searched more than once.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert to lowercase\n",
    "    query = query.lower()\n",
    "    \n",
    "    # Step 2: Remove punctuation\n",
    "    query = query.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Step 3: Split words\n",
    "    words = query.split()\n",
    "    \n",
    "    # Step 4: Count frequency\n",
    "    frequency = {}\n",
    "    for word in words:\n",
    "        frequency[word] = frequency.get(word, 0) + 1\n",
    "    \n",
    "    # Step 5: Filter keywords appearing more than once\n",
    "    repeated_keywords = {word: count for word, count in frequency.items() if count > 1}\n",
    "    \n",
    "    print(repeated_keywords)\n",
    "\n",
    "\n",
    "# Input\n",
    "query = \"Buy mobile phone buy phone online\"\n",
    "keyword_analysis(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba9e3d-521c-4836-b893-605fd426baf6",
   "metadata": {},
   "source": [
    "# Problem 3: Sensor Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1468dca1-a0a1-49ee-baed-8f4a0131d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Sensor Readings (Hour, Value):\n",
      "[(1, 4), (3, 8), (4, 10), (5, 12)]\n"
     ]
    }
   ],
   "source": [
    "# Problem 3: Sensor Data Validation\n",
    "\n",
    "def validate_sensor_data(sensor_readings):\n",
    "    \"\"\"\n",
    "    Identifies valid (even) sensor readings.\n",
    "    Stores them as (hour_index, reading_value) pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    valid_readings = []\n",
    "    \n",
    "    for index, value in enumerate(sensor_readings):\n",
    "        if value % 2 == 0:  # Check for even reading\n",
    "            valid_readings.append((index, value))\n",
    "    \n",
    "    print(\"Valid Sensor Readings (Hour, Value):\")\n",
    "    print(valid_readings)\n",
    "\n",
    "\n",
    "# Input\n",
    "sensor_readings = [3, 4, 7, 8, 10, 12, 5]\n",
    "validate_sensor_data(sensor_readings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a79e8-c5c7-4beb-95c3-cee53f8ebbca",
   "metadata": {},
   "source": [
    "# Problem 4: Email Domain Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef8f855-6dec-4d23-86e8-52867aef6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail.com: 60%\n",
      "yahoo.com: 40%\n"
     ]
    }
   ],
   "source": [
    "# Problem 4: Email Domain Usage Analysis\n",
    "\n",
    "def email_domain_analysis(emails):\n",
    "    \"\"\"\n",
    "    Calculates percentage usage of each email domain.\n",
    "    \"\"\"\n",
    "    \n",
    "    domain_count = {}\n",
    "    \n",
    "    # Count domains\n",
    "    for email in emails:\n",
    "        domain = email.split(\"@\")[1]\n",
    "        domain_count[domain] = domain_count.get(domain, 0) + 1\n",
    "    \n",
    "    total_users = len(emails)\n",
    "    \n",
    "    # Calculate percentage\n",
    "    for domain, count in domain_count.items():\n",
    "        percentage = (count / total_users) * 100\n",
    "        print(f\"{domain}: {percentage:.0f}%\")\n",
    "\n",
    "\n",
    "# Input\n",
    "emails = [\n",
    "    \"ravi@gmail.com\",\n",
    "    \"anita@yahoo.com\",\n",
    "    \"kiran@gmail.com\",\n",
    "    \"suresh@gmail.com\",\n",
    "    \"meena@yahoo.com\"\n",
    "]\n",
    "\n",
    "email_domain_analysis(emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2caec0d-5e40-4e0f-ae55-20509870677b",
   "metadata": {},
   "source": [
    "# Problem 5: Sales Spike Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8611eaa-b517-4e80-ad2a-bfb7e7f3a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 6: 3000\n"
     ]
    }
   ],
   "source": [
    "# Problem 5: Sales Spike Detection\n",
    "\n",
    "def sales_spike_detection(sales):\n",
    "    \"\"\"\n",
    "    Detects days where sales are more than 30% above average.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Calculate average\n",
    "    average_sales = sum(sales) / len(sales)\n",
    "    \n",
    "    # Step 2: Threshold (30% above average)\n",
    "    threshold = average_sales * 1.3\n",
    "    \n",
    "    # Step 3: Detect spikes\n",
    "    for day, value in enumerate(sales, start=1):\n",
    "        if value > threshold:\n",
    "            print(f\"Day {day}: {value}\")\n",
    "\n",
    "\n",
    "# Input\n",
    "sales = [1200, 1500, 900, 2200, 1400, 3000]\n",
    "sales_spike_detection(sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379577db-c00a-4688-894d-c3df15acded3",
   "metadata": {},
   "source": [
    "# Problem 6: Duplicate User ID Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c212d3-5d47-41cb-8e8e-0b2db024ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user1 → 3 times\n",
      "user3 → 2 times\n"
     ]
    }
   ],
   "source": [
    "# Problem 6: Duplicate User ID Detection\n",
    "\n",
    "def duplicate_user_detection(user_ids):\n",
    "    \"\"\"\n",
    "    Identifies duplicate user IDs and counts occurrences.\n",
    "    \"\"\"\n",
    "    \n",
    "    frequency = {}\n",
    "    \n",
    "    for user in user_ids:\n",
    "        frequency[user] = frequency.get(user, 0) + 1\n",
    "    \n",
    "    # Display duplicates only\n",
    "    for user, count in frequency.items():\n",
    "        if count > 1:\n",
    "            print(f\"{user} → {count} times\")\n",
    "\n",
    "\n",
    "# Input\n",
    "user_ids = [\"user1\", \"user2\", \"user1\", \"user3\", \"user1\", \"user3\"]\n",
    "duplicate_user_detection(user_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
